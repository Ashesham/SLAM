{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "APE NP\n",
    "'''\n",
    "\n",
    "import csv, binascii\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from evo.core.trajectory import PosePath3D, PoseTrajectory3D\n",
    "from evo.core import lie_algebra, sync, metrics\n",
    "from evo.core.metrics import PoseRelation, Unit\n",
    "import typing\n",
    "import scipy.spatial.transform as sst\n",
    "from distutils.version import LooseVersion\n",
    "from scipy import __version__ as scipy_version\n",
    "from enum import Enum\n",
    "\n",
    "_USE_DCM_NAME = LooseVersion(scipy_version) < LooseVersion(\"1.4\")\n",
    "\n",
    "def csv_read_matrix(file_path, delim=',', comment_str=\"#\"):\n",
    "    \"\"\"\n",
    "    directly parse a csv-like file into a matrix\n",
    "    :param file_path: path of csv file (or file handle)\n",
    "    :param delim: delimiter character\n",
    "    :param comment_str: string indicating a comment line to ignore\n",
    "    :return: 2D list with raw data (string)\n",
    "    \"\"\"\n",
    "    if hasattr(file_path, 'read'):  # if file handle\n",
    "        generator = (line for line in file_path\n",
    "                     if not line.startswith(comment_str))\n",
    "        reader = csv.reader(generator, delimiter=delim)\n",
    "        mat = [row for row in reader]\n",
    "    else:\n",
    "        skip_3_bytes = has_utf8_bom(file_path)\n",
    "        with open(file_path) as f:\n",
    "            if skip_3_bytes:\n",
    "                f.seek(3)\n",
    "            generator = (line for line in f\n",
    "                         if not line.startswith(comment_str))\n",
    "            reader = csv.reader(generator, delimiter=delim)\n",
    "            mat = [row for row in reader]\n",
    "    return mat\n",
    "\n",
    "def has_utf8_bom(file_path):\n",
    "    \"\"\"\n",
    "    Checks if the given file starts with a UTF8 BOM\n",
    "    wikipedia.org/wiki/Byte_order_mark\n",
    "    \"\"\"\n",
    "    size_bytes = os.path.getsize(file_path)\n",
    "    if size_bytes < 3:\n",
    "        return False\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return not int(binascii.hexlify(f.read(3)), 16) ^ 0xEFBBBF\n",
    "\n",
    "def get_trajs(f_path):\n",
    "    raw_mat = csv_read_matrix(f_path,delim=' ')\n",
    "    error_msg = \"TUM trajectory files must have 8 entries per row and no trailing delimiter at the end of the rows (space)\"\n",
    "    if not raw_mat or (len(raw_mat) > 0 and len(raw_mat[0]) != 8):\n",
    "        raise error_msg\n",
    "    try:\n",
    "        mat = np.array(raw_mat).astype(float)\n",
    "    except ValueError:\n",
    "        raise error_msg\n",
    "    stamps = mat[:, 0]  # n x 1\n",
    "    xyz = mat[:, 1:4]  # n x 3\n",
    "    quat = mat[:, 4:]  # n x 4\n",
    "    quat = np.roll(quat, 1, axis=1)  # shift 1 column -> w in front column\n",
    "    return PoseTrajectory3D(xyz,quat,stamps)\n",
    "\n",
    "def sim3(r: np.ndarray, t: np.ndarray, s: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param r: SO(3) rotation matrix\n",
    "    :param t: 3x1 translation vector\n",
    "    :param s: positive, non-zero scale factor\n",
    "    :return: Sim(3) similarity transformation matrix\n",
    "    \"\"\"\n",
    "    sim3 = np.eye(4)\n",
    "    sim3[:3, :3] = s * r\n",
    "    sim3[:3, 3] = t\n",
    "    return sim3\n",
    "\n",
    "def relative_se3(p1: np.ndarray, p2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param p1, p2: SE(3) matrices\n",
    "    :return: the relative transformation p1^{⁻1} * p2\n",
    "    \"\"\"\n",
    "    return np.dot(se3_inverse(p1), p2)\n",
    "\n",
    "def se3_inverse(p: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param p: absolute SE(3) pose\n",
    "    :return: the inverted pose\n",
    "    \"\"\"\n",
    "    r_inv = p[:3, :3].transpose()\n",
    "    t_inv = -r_inv.dot(p[:3, 3])\n",
    "    return se3(r_inv, t_inv)\n",
    "\n",
    "def se3(r: np.ndarray = np.eye(3),\n",
    "        t: np.ndarray = np.array([0, 0, 0])) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    :param r: SO(3) rotation matrix\n",
    "    :param t: 3x1 translation vector\n",
    "    :return: SE(3) transformation matrix\n",
    "    \"\"\"\n",
    "    se3 = np.eye(4)\n",
    "    se3[:3, :3] = r\n",
    "    se3[:3, 3] = t\n",
    "    return se3\n",
    "\n",
    "def umeyama_alignment(x: np.ndarray, y: np.ndarray,\n",
    "                      with_scale: bool = False):\n",
    "    \"\"\"\n",
    "    Computes the least squares solution parameters of an Sim(m) matrix\n",
    "    that minimizes the distance between a set of registered points.\n",
    "    Umeyama, Shinji: Least-squares estimation of transformation parameters\n",
    "                     between two point patterns. IEEE PAMI, 1991\n",
    "    :param x: mxn matrix of points, m = dimension, n = nr. of data points\n",
    "    :param y: mxn matrix of points, m = dimension, n = nr. of data points\n",
    "    :param with_scale: set to True to align also the scale (default: 1.0 scale)\n",
    "    :return: r, t, c - rotation matrix, translation vector and scale factor\n",
    "    \"\"\"\n",
    "    if x.shape != y.shape:\n",
    "        raise \"data matrices must have the same shape\"\n",
    "\n",
    "    # m = dimension, n = nr. of data points\n",
    "    m, n = x.shape\n",
    "\n",
    "    # means, eq. 34 and 35\n",
    "    mean_x = x.mean(axis=1)\n",
    "    mean_y = y.mean(axis=1)\n",
    "\n",
    "    # variance, eq. 36\n",
    "    # \"transpose\" for column subtraction\n",
    "    sigma_x = 1.0 / n * (np.linalg.norm(x - mean_x[:, np.newaxis])**2)\n",
    "\n",
    "    # covariance matrix, eq. 38\n",
    "    outer_sum = np.zeros((m, m))\n",
    "    for i in range(n):\n",
    "        outer_sum += np.outer((y[:, i] - mean_y), (x[:, i] - mean_x))\n",
    "    cov_xy = np.multiply(1.0 / n, outer_sum)\n",
    "\n",
    "    # SVD (text betw. eq. 38 and 39)\n",
    "    u, d, v = np.linalg.svd(cov_xy)\n",
    "    if np.count_nonzero(d > np.finfo(d.dtype).eps) < m - 1:\n",
    "        raise \"Degenerate covariance rank, Umeyama alignment is not possible\"\n",
    "\n",
    "    # S matrix, eq. 43\n",
    "    s = np.eye(m)\n",
    "    if np.linalg.det(u) * np.linalg.det(v) < 0.0:\n",
    "        # Ensure a RHS coordinate system (Kabsch algorithm).\n",
    "        s[m - 1, m - 1] = -1\n",
    "\n",
    "    # rotation, eq. 40\n",
    "    r = u.dot(s).dot(v)\n",
    "\n",
    "    # scale & translation, eq. 42 and 41\n",
    "    c = 1 / sigma_x * np.trace(np.diag(d).dot(s)) if with_scale else 1.0\n",
    "    t = mean_y - np.multiply(c, r.dot(mean_x))\n",
    "\n",
    "    return r, t, c\n",
    "\n",
    "def scale(s: float, _poses_se3, _positions_xyz) -> None:\n",
    "    \"\"\"\n",
    "    apply a scaling to the whole path\n",
    "    :param s: scale factor\n",
    "    \"\"\"\n",
    "    # if hasattr(self, \"_poses_se3\"):\n",
    "    _poses_se3 = [\n",
    "        se3(p[:3, :3], s * p[:3, 3]) for p in _poses_se3\n",
    "    ]\n",
    "    # if hasattr(self, \"_positions_xyz\"):\n",
    "    _positions_xyz = s * _positions_xyz\n",
    "\n",
    "    return _poses_se3, _positions_xyz\n",
    "\n",
    "def quaternion_from_matrix(matrix, isprecise=False):\n",
    "    \"\"\"Return quaternion from rotation matrix.\n",
    "\n",
    "    If isprecise is True, the input matrix is assumed to be a precise rotation\n",
    "    matrix and a faster algorithm is used.\n",
    "\n",
    "    >>> q = quaternion_from_matrix(np.identity(4), True)\n",
    "    >>> np.allclose(q, [1, 0, 0, 0])\n",
    "    True\n",
    "    >>> q = quaternion_from_matrix(np.diag([1, -1, -1, 1]))\n",
    "    >>> np.allclose(q, [0, 1, 0, 0]) or np.allclose(q, [0, -1, 0, 0])\n",
    "    True\n",
    "    >>> R = rotation_matrix(0.123, (1, 2, 3))\n",
    "    >>> q = quaternion_from_matrix(R, True)\n",
    "    >>> np.allclose(q, [0.9981095, 0.0164262, 0.0328524, 0.0492786])\n",
    "    True\n",
    "    >>> R = [[-0.545, 0.797, 0.260, 0], [0.733, 0.603, -0.313, 0],\n",
    "    ...      [-0.407, 0.021, -0.913, 0], [0, 0, 0, 1]]\n",
    "    >>> q = quaternion_from_matrix(R)\n",
    "    >>> np.allclose(q, [0.19069, 0.43736, 0.87485, -0.083611])\n",
    "    True\n",
    "    >>> R = [[0.395, 0.362, 0.843, 0], [-0.626, 0.796, -0.056, 0],\n",
    "    ...      [-0.677, -0.498, 0.529, 0], [0, 0, 0, 1]]\n",
    "    >>> q = quaternion_from_matrix(R)\n",
    "    >>> np.allclose(q, [0.82336615, -0.13610694, 0.46344705, -0.29792603])\n",
    "    True\n",
    "    >>> R = random_rotation_matrix()\n",
    "    >>> q = quaternion_from_matrix(R)\n",
    "    >>> is_same_transform(R, quaternion_matrix(q))\n",
    "    True\n",
    "    >>> R = euler_matrix(0.0, 0.0, np.pi/2.0)\n",
    "    >>> np.allclose(quaternion_from_matrix(R, isprecise=False),\n",
    "    ...                quaternion_from_matrix(R, isprecise=True))\n",
    "    True\n",
    "\n",
    "    \"\"\"\n",
    "    M = np.array(matrix, dtype=np.float64, copy=False)[:4, :4]\n",
    "    if isprecise:\n",
    "        q = np.empty((4, ))\n",
    "        t = np.trace(M)\n",
    "        if t > M[3, 3]:\n",
    "            q[0] = t\n",
    "            q[3] = M[1, 0] - M[0, 1]\n",
    "            q[2] = M[0, 2] - M[2, 0]\n",
    "            q[1] = M[2, 1] - M[1, 2]\n",
    "        else:\n",
    "            i, j, k = 1, 2, 3\n",
    "            if M[1, 1] > M[0, 0]:\n",
    "                i, j, k = 2, 3, 1\n",
    "            if M[2, 2] > M[i, i]:\n",
    "                i, j, k = 3, 1, 2\n",
    "            t = M[i, i] - (M[j, j] + M[k, k]) + M[3, 3]\n",
    "            q[i] = t\n",
    "            q[j] = M[i, j] + M[j, i]\n",
    "            q[k] = M[k, i] + M[i, k]\n",
    "            q[3] = M[k, j] - M[j, k]\n",
    "        q *= 0.5 / math.sqrt(t * M[3, 3])\n",
    "    else:\n",
    "        m00 = M[0, 0]\n",
    "        m01 = M[0, 1]\n",
    "        m02 = M[0, 2]\n",
    "        m10 = M[1, 0]\n",
    "        m11 = M[1, 1]\n",
    "        m12 = M[1, 2]\n",
    "        m20 = M[2, 0]\n",
    "        m21 = M[2, 1]\n",
    "        m22 = M[2, 2]\n",
    "        # symmetric matrix K\n",
    "        K = np.array([[m00-m11-m22, 0.0,         0.0,         0.0],\n",
    "                         [m01+m10,     m11-m00-m22, 0.0,         0.0],\n",
    "                         [m02+m20,     m12+m21,     m22-m00-m11, 0.0],\n",
    "                         [m21-m12,     m02-m20,     m10-m01,     m00+m11+m22]])\n",
    "        K /= 3.0\n",
    "        # quaternion is eigenvector of K that corresponds to largest eigenvalue\n",
    "        w, V = np.linalg.eigh(K)\n",
    "        q = V[[3, 0, 1, 2], np.argmax(w)]\n",
    "    if q[0] < 0.0:\n",
    "        np.negative(q, q)\n",
    "    return q\n",
    "\n",
    "def se3_poses_to_xyz_quat_wxyz(\n",
    "    poses: typing.Sequence[np.ndarray]\n",
    ") -> typing.Tuple[np.ndarray, np.ndarray]:\n",
    "    xyz = np.array([pose[:3, 3] for pose in poses])\n",
    "    quat_wxyz = np.array([quaternion_from_matrix(pose) for pose in poses])\n",
    "    return xyz, quat_wxyz\n",
    "\n",
    "def transform(t: np.ndarray, poses_se3, right_mul: bool = False,\n",
    "                propagate: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    apply a left or right multiplicative transformation to the whole path\n",
    "    :param t: a 4x4 transformation matrix (e.g. SE(3) or Sim(3))\n",
    "    :param right_mul: whether to apply it right-multiplicative or not\n",
    "    :param propagate: whether to propagate drift with RHS transformations\n",
    "    \"\"\"\n",
    "    num_poses = len(poses_se3)\n",
    "    if right_mul and not propagate:\n",
    "        # Transform each pose individually.\n",
    "        _poses_se3 = [np.dot(p, t) for p in poses_se3]\n",
    "    elif right_mul and propagate:\n",
    "        # Transform each pose and propagate resulting drift to the next.\n",
    "        ids = np.arange(0, num_poses, 1)\n",
    "        rel_poses = [\n",
    "            relative_se3(poses_se3[i], poses_se3[j]).dot(t)\n",
    "            for i, j in zip(ids, ids[1:])\n",
    "        ]\n",
    "        _poses_se3 = [poses_se3[0]]\n",
    "        for i, j in zip(ids[:-1], ids):\n",
    "            _poses_se3.append(_poses_se3[j].dot(rel_poses[i]))\n",
    "    else:\n",
    "        _poses_se3 = [np.dot(t, p) for p in poses_se3]\n",
    "    return _poses_se3\n",
    "    # _positions_xyz, _orientations_quat_wxyz \\\n",
    "    #     = se3_poses_to_xyz_quat_wxyz(poses_se3)\n",
    "def align_traj(traj_ref,traj_est, correct_scale: bool = False,\n",
    "            correct_only_scale: bool = False, n: int = -1):\n",
    "    \"\"\"\n",
    "    align to a reference trajectory using Umeyama alignment\n",
    "    :param traj_ref: reference trajectory\n",
    "    :param correct_scale: set to True to adjust also the scale\n",
    "    :param correct_only_scale: set to True to correct the scale, but not the pose\n",
    "    :param n: the number of poses to use, counted from the start (default: all)\n",
    "    :return: the result parameters of the Umeyama algorithm\n",
    "    \"\"\"\n",
    "    with_scale = correct_scale or correct_only_scale\n",
    "    if n == -1:\n",
    "        r_a, t_a, s = umeyama_alignment(traj_est[:,:3,3].T, traj_ref[:,:3,3].T, with_scale)\n",
    "    else:\n",
    "        r_a, t_a, s = umeyama_alignment(\n",
    "            traj_est[:n,:3,3].T, traj_est[:n, :3,3].T,\n",
    "            with_scale)\n",
    "\n",
    "    poses_se3, positions_xyz = traj_est, traj_est[:,:3,3]\n",
    "\n",
    "    if correct_only_scale:\n",
    "        poses_se3, positions_xyz = scale(s,poses_se3,positions_xyz)\n",
    "    elif correct_scale:\n",
    "        poses_se3, positions_xyz = scale(s,poses_se3,positions_xyz)\n",
    "        poses_se3 = transform(se3(r_a, t_a),poses_se3)\n",
    "    else:\n",
    "        poses_se3 = transform(se3(r_a, t_a),poses_se3)\n",
    "    # traj_est.poses_se3, traj_est.positions_xyz = poses_se3, positions_xyz \n",
    "\n",
    "    return poses_se3\n",
    "\n",
    "def align_origin_traj(traj_ref, traj_est) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        align the origin to the origin of a reference trajectory\n",
    "        :param traj_ref: reference trajectory\n",
    "        :return: the used transformation\n",
    "        \"\"\"\n",
    "        traj_origin = traj_est[0]\n",
    "        traj_ref_origin = traj_ref[0]\n",
    "        to_ref_origin = np.dot(traj_ref_origin, se3_inverse(traj_origin))\n",
    "        return to_ref_origin\n",
    "\n",
    "def ape(traj_ref, traj_est, align: bool = False, correct_scale: bool = False, \n",
    "        n_to_align: int = -1, align_origin: bool = False):\n",
    "\n",
    "    # Align the trajectories.\n",
    "    only_scale = correct_scale and not align\n",
    "\n",
    "    if align or correct_scale:\n",
    "        traj_est = align_traj(traj_ref,traj_est, correct_scale, only_scale, n=n_to_align)\n",
    "    elif align_origin:\n",
    "        alignment_transformation = align_origin_traj(traj_ref, traj_est)\n",
    "        traj_est = transform(alignment_transformation,traj_est)\n",
    "\n",
    "    # Calculate APE.\n",
    "    data = (traj_ref, traj_est)\n",
    "    E = [\n",
    "        relative_se3(x_t, x_t_star) for x_t, x_t_star in zip(\n",
    "            traj_est, traj_ref)\n",
    "    ]\n",
    "    error = np.array(\n",
    "        [np.linalg.norm(E_i - np.eye(4)) for E_i in E])\n",
    "\n",
    "    squared_errors = np.power(error, 2)\n",
    "    rmse = math.sqrt(np.mean(squared_errors))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "groundtruth_file = '/home/rp2/Projects/slambook2/ch4/example/groundtruth.txt'\n",
    "estimated_file = '/home/rp2/Projects/slambook2/ch4/example/estimated.txt'\n",
    "\n",
    "traj_ref, traj_est, ref_name, est_name = get_trajs(groundtruth_file), get_trajs(estimated_file), groundtruth_file, estimated_file\n",
    "traj_ref, traj_est = sync.associate_trajectories(traj_ref, traj_est)\n",
    "traj_ref, traj_est = np.array(traj_ref.poses_se3), np.array(traj_est.poses_se3)\n",
    "pose_relation = PoseRelation.full_transformation\n",
    "res = ape(traj_ref=traj_ref, traj_est=traj_est, align=True, correct_scale=True)\n",
    "\"Result APE: \", res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "def ape(traj_ref, traj_est, align: bool = False, correct_scale: bool = False, \n",
    "        n_to_align: int = -1, align_origin: bool = False):\n",
    "\n",
    "    # Align the trajectories.\n",
    "    only_scale = correct_scale and not align\n",
    "\n",
    "    if align or correct_scale:\n",
    "        traj_est = align_traj(traj_ref,traj_est, correct_scale, only_scale, n=n_to_align)\n",
    "    elif align_origin:\n",
    "        alignment_transformation = align_origin_traj(traj_ref, traj_est)\n",
    "        traj_est = transform(alignment_transformation,traj_est)\n",
    "\n",
    "    # Calculate APE.\n",
    "    data = (traj_ref, traj_est)\n",
    "    E = [\n",
    "        relative_se3(x_t, x_t_star) for x_t, x_t_star in zip(\n",
    "            traj_est, traj_ref)\n",
    "    ]\n",
    "    E_ = [R.from_matrix(i[:3,:3]) for i in E]\n",
    "    error = [np.array([np.concatenate((E_[i].as_rotvec(),E[i][:3,3]))]) for i in range(len(E))]\n",
    "\n",
    "    squared_errors = np.power(error, 2)\n",
    "    rmse = math.sqrt(np.mean(squared_errors))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "groundtruth_file = '/home/rp2/Projects/slambook2/ch4/example/groundtruth.txt'\n",
    "estimated_file = '/home/rp2/Projects/slambook2/ch4/example/estimated.txt'\n",
    "\n",
    "traj_ref, traj_est, ref_name, est_name = get_trajs(groundtruth_file), get_trajs(estimated_file), groundtruth_file, estimated_file\n",
    "traj_ref, traj_est = sync.associate_trajectories(traj_ref, traj_est)\n",
    "traj_ref, traj_est = np.array(traj_ref.poses_se3), np.array(traj_est.poses_se3)\n",
    "pose_relation = PoseRelation.full_transformation\n",
    "res = ape(traj_ref=traj_ref, traj_est=traj_est, align=True, correct_scale=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "'''Good Info'''\n",
    "# theta = r.as_rotvec(degrees=True)\n",
    "# a = r/np.linalg(r.as_rotvec(degrees=True))\n",
    "for i in range(420,len(traj_est)):\n",
    "    print(i,end='')\n",
    "    r = R.from_matrix(traj_est[i,:3,:3])\n",
    "    quat = r.as_quat()\n",
    "    angle = 2 * np.arctan2(np.linalg.norm(quat), quat[3])\n",
    "\n",
    "    if angle <= 1e-3:  # small angle Taylor series expansion\n",
    "        angle2 = angle * angle\n",
    "        scale = 2 + angle2 / 12 + 7 * angle2 * angle2 / 2880\n",
    "    else:  # large angle\n",
    "        scale = angle / np.sin(angle / 2)\n",
    "        print('L',end='')\n",
    "\n",
    "    rotvec = scale * quat[:3]\n",
    "    print(rotvec,r.as_rotvec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((r.as_rotvec(),r.as_rotvec()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, binascii\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from evo.core.trajectory import PosePath3D, PoseTrajectory3D\n",
    "from evo.core import lie_algebra, sync, metrics\n",
    "from evo.core.metrics import PoseRelation, Unit\n",
    "import typing\n",
    "import scipy.spatial.transform as sst\n",
    "from distutils.version import LooseVersion\n",
    "from scipy import __version__ as scipy_version\n",
    "from enum import Enum\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(precision=6)\n",
    "\n",
    "_USE_DCM_NAME = LooseVersion(scipy_version) < LooseVersion(\"1.4\")\n",
    "\n",
    "def csv_read_matrix(file_path, delim=',', comment_str=\"#\"):\n",
    "    \"\"\"\n",
    "    directly parse a csv-like file into a matrix\n",
    "    :param file_path: path of csv file (or file handle)\n",
    "    :param delim: delimiter character\n",
    "    :param comment_str: string indicating a comment line to ignore\n",
    "    :return: 2D list with raw data (string)\n",
    "    \"\"\"\n",
    "    if hasattr(file_path, 'read'):  # if file handle\n",
    "        generator = (line for line in file_path\n",
    "                     if not line.startswith(comment_str))\n",
    "        reader = csv.reader(generator, delimiter=delim)\n",
    "        mat = [row for row in reader]\n",
    "    else:\n",
    "        skip_3_bytes = has_utf8_bom(file_path)\n",
    "        with open(file_path) as f:\n",
    "            if skip_3_bytes:\n",
    "                f.seek(3)\n",
    "            generator = (line for line in f\n",
    "                         if not line.startswith(comment_str))\n",
    "            reader = csv.reader(generator, delimiter=delim)\n",
    "            mat = [row for row in reader]\n",
    "    return mat\n",
    "\n",
    "def has_utf8_bom(file_path):\n",
    "    \"\"\"\n",
    "    Checks if the given file starts with a UTF8 BOM\n",
    "    wikipedia.org/wiki/Byte_order_mark\n",
    "    \"\"\"\n",
    "    size_bytes = os.path.getsize(file_path)\n",
    "    if size_bytes < 3:\n",
    "        return False\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return not int(binascii.hexlify(f.read(3)), 16) ^ 0xEFBBBF\n",
    "\n",
    "def get_trajs(f_path):\n",
    "    raw_mat = csv_read_matrix(f_path,delim=' ')\n",
    "    error_msg = \"TUM trajectory files must have 8 entries per row and no trailing delimiter at the end of the rows (space)\"\n",
    "    if not raw_mat or (len(raw_mat) > 0 and len(raw_mat[0]) != 8):\n",
    "        raise error_msg\n",
    "    try:\n",
    "        mat = np.array(raw_mat).astype(float)\n",
    "    except ValueError:\n",
    "        raise error_msg\n",
    "    stamps = mat[:, 0]  # n x 1\n",
    "    xyz = mat[:, 1:4]  # n x 3\n",
    "    quat = mat[:, 4:]  # n x 4\n",
    "    quat = np.roll(quat, 1, axis=1)  # shift 1 column -> w in front column\n",
    "    return PoseTrajectory3D(xyz,quat,stamps)\n",
    "\n",
    "def sim3(r: torch.tensor, t: torch.tensor, s: float) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    :param r: SO(3) rotation matrix\n",
    "    :param t: 3x1 translation vector\n",
    "    :param s: positive, non-zero scale factor\n",
    "    :return: Sim(3) similarity transformation matrix\n",
    "    \"\"\"\n",
    "    sim3 = torch.eye(4)\n",
    "    sim3[:3, :3] = s * r\n",
    "    sim3[:3, 3] = t\n",
    "    return sim3\n",
    "\n",
    "def relative_se3(p1: torch.tensor, p2: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    :param p1, p2: SE(3) matrices\n",
    "    :return: the relative transformation p1^{⁻1} * p2\n",
    "    \"\"\"\n",
    "    return se3_inverse(p1)@ p2\n",
    "\n",
    "def se3_inverse(p: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    :param p: absolute SE(3) pose\n",
    "    :return: the inverted pose\n",
    "    \"\"\"\n",
    "    r_inv = p[:3, :3].T\n",
    "    t_inv = -r_inv@p[:3, 3]\n",
    "    return se3(r_inv, t_inv)\n",
    "\n",
    "def se3(r: torch.tensor = torch.eye(3),\n",
    "        t: torch.tensor = torch.tensor([0, 0, 0])) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    :param r: SO(3) rotation matrix\n",
    "    :param t: 3x1 translation vector\n",
    "    :return: SE(3) transformation matrix\n",
    "    \"\"\"\n",
    "    se3 = torch.eye(4,dtype=torch.float64)\n",
    "    se3[:3, :3] = r\n",
    "    se3[:3, 3] = t\n",
    "    return se3\n",
    "\n",
    "def umeyama_alignment(x: torch.tensor, y: torch.tensor,\n",
    "                      with_scale: bool = False):\n",
    "    \"\"\"\n",
    "    Computes the least squares solution parameters of an Sim(m) matrix\n",
    "    that minimizes the distance between a set of registered points.\n",
    "    Umeyama, Shinji: Least-squares estimation of transformation parameters\n",
    "                     between two point patterns. IEEE PAMI, 1991\n",
    "    :param x: mxn matrix of points, m = dimension, n = nr. of data points\n",
    "    :param y: mxn matrix of points, m = dimension, n = nr. of data points\n",
    "    :param with_scale: set to True to align also the scale (default: 1.0 scale)\n",
    "    :return: r, t, c - rotation matrix, translation vector and scale factor\n",
    "    \"\"\"\n",
    "    if x.shape != y.shape:\n",
    "        raise \"data matrices must have the same shape\"\n",
    "\n",
    "    # m = dimension, n = nr. of data points\n",
    "    m, n = x.shape\n",
    "\n",
    "    # means, eq. 34 and 35\n",
    "    mean_x = x.mean(axis=1)\n",
    "    mean_y = y.mean(axis=1)\n",
    "\n",
    "    # variance, eq. 36\n",
    "    # \"transpose\" for column subtraction\n",
    "    sigma_x = 1.0 / n * (torch.linalg.norm(x - mean_x[:, None])**2)\n",
    "\n",
    "    # covariance matrix, eq. 38\n",
    "    outer_sum = torch.zeros((m, m))\n",
    "    for i in range(n):\n",
    "        outer_sum += torch.outer((y[:, i] - mean_y), (x[:, i] - mean_x))\n",
    "    cov_xy = 1.0 / n * outer_sum\n",
    "\n",
    "    # SVD (text betw. eq. 38 and 39)\n",
    "    u, d, v = torch.linalg.svd(cov_xy)\n",
    "    if torch.count_nonzero(d > torch.finfo(d.dtype).eps) < m - 1:\n",
    "        raise \"Degenerate covariance rank, Umeyama alignment is not possible\"\n",
    "\n",
    "    # S matrix, eq. 43\n",
    "    s = torch.eye(m)\n",
    "    if torch.linalg.det(u) * torch.linalg.det(v) < 0.0:\n",
    "        # Ensure a RHS coordinate system (Kabsch algorithm).\n",
    "        s[m - 1, m - 1] = -1\n",
    "\n",
    "    # rotation, eq. 40\n",
    "    r = ((u@s)@v).to(torch.float64)\n",
    "    # scale & translation, eq. 42 and 41\n",
    "    c = 1 / sigma_x * torch.trace(torch.diag(d)@s) if with_scale else 1.0\n",
    "    t = mean_y - torch.multiply(c, r@mean_x)\n",
    "\n",
    "    return r, t, c\n",
    "\n",
    "def scale(s: float, _poses_se3, _positions_xyz) -> None:\n",
    "    \"\"\"\n",
    "    apply a scaling to the whole path\n",
    "    :param s: scale factor\n",
    "    \"\"\"\n",
    "    # if hasattr(self, \"_poses_se3\"):\n",
    "    _poses_se3 = [\n",
    "        se3(p[:3, :3], s * p[:3, 3]) for p in _poses_se3\n",
    "    ]\n",
    "    # if hasattr(self, \"_positions_xyz\"):\n",
    "    _positions_xyz = s * _positions_xyz\n",
    "\n",
    "    return _poses_se3, _positions_xyz\n",
    "\n",
    "def quaternion_from_matrix(matrix, isprecise=False):\n",
    "    \"\"\"Return quaternion from rotation matrix.\n",
    "\n",
    "    If isprecise is True, the input matrix is assumed to be a precise rotation\n",
    "    matrix and a faster algorithm is used.\n",
    "    \"\"\"\n",
    "    M = torch.array(matrix, dtype=torch.float64, copy=False)[:4, :4]\n",
    "    if isprecise:\n",
    "        q = torch.empty((4, ))\n",
    "        t = torch.trace(M)\n",
    "        if t > M[3, 3]:\n",
    "            q[0] = t\n",
    "            q[3] = M[1, 0] - M[0, 1]\n",
    "            q[2] = M[0, 2] - M[2, 0]\n",
    "            q[1] = M[2, 1] - M[1, 2]\n",
    "        else:\n",
    "            i, j, k = 1, 2, 3\n",
    "            if M[1, 1] > M[0, 0]:\n",
    "                i, j, k = 2, 3, 1\n",
    "            if M[2, 2] > M[i, i]:\n",
    "                i, j, k = 3, 1, 2\n",
    "            t = M[i, i] - (M[j, j] + M[k, k]) + M[3, 3]\n",
    "            q[i] = t\n",
    "            q[j] = M[i, j] + M[j, i]\n",
    "            q[k] = M[k, i] + M[i, k]\n",
    "            q[3] = M[k, j] - M[j, k]\n",
    "        q *= 0.5 / math.sqrt(t * M[3, 3])\n",
    "    else:\n",
    "        m00 = M[0, 0]\n",
    "        m01 = M[0, 1]\n",
    "        m02 = M[0, 2]\n",
    "        m10 = M[1, 0]\n",
    "        m11 = M[1, 1]\n",
    "        m12 = M[1, 2]\n",
    "        m20 = M[2, 0]\n",
    "        m21 = M[2, 1]\n",
    "        m22 = M[2, 2]\n",
    "        # symmetric matrix K\n",
    "        K = torch.array([[m00-m11-m22, 0.0,         0.0,         0.0],\n",
    "                         [m01+m10,     m11-m00-m22, 0.0,         0.0],\n",
    "                         [m02+m20,     m12+m21,     m22-m00-m11, 0.0],\n",
    "                         [m21-m12,     m02-m20,     m10-m01,     m00+m11+m22]])\n",
    "        K /= 3.0\n",
    "        # quaternion is eigenvector of K that corresponds to largest eigenvalue\n",
    "        w, V = torch.linalg.eigh(K)\n",
    "        q = V[[3, 0, 1, 2], torch.argmax(w)]\n",
    "    if q[0] < 0.0:\n",
    "        torch.negative(q, q)\n",
    "    return q\n",
    "\n",
    "def se3_poses_to_xyz_quat_wxyz(\n",
    "    poses: typing.Sequence[torch.tensor]\n",
    ") -> typing.Tuple[torch.tensor, torch.tensor]:\n",
    "    xyz = torch.tensor([pose[:3, 3] for pose in poses],requires_grad=True)\n",
    "    quat_wxyz = torch.tensor([quaternion_from_matrix(pose) for pose in poses],requires_grad=True)\n",
    "    return xyz, quat_wxyz\n",
    "\n",
    "def transform(t: torch.tensor, poses_se3, right_mul: bool = False,\n",
    "                propagate: bool = False) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    apply a left or right multiplicative transformation to the whole path\n",
    "    :param t: a 4x4 transformation matrix (e.g. SE(3) or Sim(3))\n",
    "    :param right_mul: whether to apply it right-multiplicative or not\n",
    "    :param propagate: whether to propagate drift with RHS transformations\n",
    "    \"\"\"\n",
    "    num_poses = len(poses_se3)\n",
    "    if right_mul and not propagate:\n",
    "        # Transform each pose individually.\n",
    "        _poses_se3 = [p@t for p in poses_se3]\n",
    "    elif right_mul and propagate:\n",
    "        # Transform each pose and propagate resulting drift to the next.\n",
    "        ids = torch.arange(0, num_poses, 1)\n",
    "        rel_poses = [\n",
    "            relative_se3(poses_se3[i], poses_se3[j]).dot(t)\n",
    "            for i, j in zip(ids, ids[1:])\n",
    "        ]\n",
    "        _poses_se3 = [poses_se3[0]]\n",
    "        for i, j in zip(ids[:-1], ids):\n",
    "            _poses_se3.append(_poses_se3[j].dot(rel_poses[i]))\n",
    "    else:\n",
    "        _poses_se3 = [t@p for p in poses_se3]\n",
    "    return _poses_se3\n",
    "\n",
    "def align_traj(traj_ref,traj_est, correct_scale: bool = False,\n",
    "            correct_only_scale: bool = False, n: int = -1):\n",
    "    \"\"\"\n",
    "    align to a reference trajectory using Umeyama alignment\n",
    "    :param traj_ref: reference trajectory\n",
    "    :param correct_scale: set to True to adjust also the scale\n",
    "    :param correct_only_scale: set to True to correct the scale, but not the pose\n",
    "    :param n: the number of poses to use, counted from the start (default: all)\n",
    "    :return: aligned trajectory\n",
    "    \"\"\"\n",
    "    with_scale = correct_scale or correct_only_scale\n",
    "    if n == -1:\n",
    "        r_a, t_a, s = umeyama_alignment(traj_est[:,:3,3].T, traj_ref[:,:3,3].T, with_scale)\n",
    "    else:\n",
    "        r_a, t_a, s = umeyama_alignment(\n",
    "            traj_est[:n,:3,3].T, traj_est[:n, :3,3].T,\n",
    "            with_scale)\n",
    "\n",
    "    poses_se3, positions_xyz = traj_est, traj_est[:,:3,3]\n",
    "\n",
    "    if correct_only_scale:\n",
    "        poses_se3, positions_xyz = scale(s,poses_se3,positions_xyz)\n",
    "    elif correct_scale:\n",
    "        poses_se3, positions_xyz = scale(s,poses_se3,positions_xyz)\n",
    "        poses_se3 = transform(se3(r_a, t_a),poses_se3)\n",
    "    else:\n",
    "        poses_se3 = transform(se3(r_a, t_a),poses_se3)\n",
    "    # traj_est.poses_se3, traj_est.positions_xyz = poses_se3, positions_xyz \n",
    "\n",
    "    return poses_se3\n",
    "\n",
    "def align_origin_traj(traj_ref, traj_est) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        align the origin to the origin of a reference trajectory\n",
    "        :param traj_ref: reference trajectory\n",
    "        :return: the used transformation\n",
    "        \"\"\"\n",
    "        traj_origin = traj_est[0]\n",
    "        traj_ref_origin = traj_ref[0]\n",
    "        to_ref_origin = traj_ref_origin@se3_inverse(traj_origin)\n",
    "        return to_ref_origin\n",
    "\n",
    "def ape(traj_ref, traj_est, align: bool = False, correct_scale: bool = False, \n",
    "        n_to_align: int = -1, align_origin: bool = False):\n",
    "\n",
    "    # Align the trajectories.\n",
    "    only_scale = correct_scale and not align\n",
    "    \n",
    "    if align or correct_scale:\n",
    "        traj_est = align_traj(traj_ref,traj_est, correct_scale, only_scale, n=n_to_align)\n",
    "    elif align_origin:\n",
    "        alignment_transformation = align_origin_traj(traj_ref, traj_est)\n",
    "        traj_est = transform(alignment_transformation,traj_est)\n",
    "    # Calculate APE.\n",
    "    data = (traj_ref, traj_est)\n",
    "    E = [\n",
    "        relative_se3(x_t, x_t_star) for x_t, x_t_star in zip(\n",
    "            traj_est, traj_ref)\n",
    "    ]\n",
    "    \n",
    "    error = torch.tensor(\n",
    "        [(E_i - torch.eye(4)).pow(2).sum().sqrt() for E_i in E], requires_grad=True)\n",
    "\n",
    "    squared_errors = torch.pow(error, 2)\n",
    "    rmse = torch.sqrt(torch.mean(squared_errors))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "groundtruth_file = '/home/rp2/Projects/slambook2/ch4/example/groundtruth.txt'\n",
    "estimated_file = '/home/rp2/Projects/slambook2/ch4/example/estimated.txt'\n",
    "\n",
    "traj_ref, traj_est, ref_name, est_name = get_trajs(groundtruth_file), get_trajs(estimated_file), groundtruth_file, estimated_file\n",
    "traj_ref, traj_est = sync.associate_trajectories(traj_ref, traj_est)\n",
    "traj_ref, traj_est = torch.tensor(traj_ref.poses_se3, requires_grad=True, dtype=torch.float64), torch.tensor(traj_est.poses_se3, requires_grad=True, dtype=torch.float64)\n",
    "res = ape(traj_ref=traj_ref, traj_est=traj_est,align=True, correct_scale=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, binascii\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from evo.core.trajectory import PosePath3D, PoseTrajectory3D\n",
    "from evo.core import lie_algebra, sync, metrics\n",
    "from evo.core.metrics import PoseRelation, Unit\n",
    "import typing\n",
    "import scipy.spatial.transform as sst\n",
    "from distutils.version import LooseVersion\n",
    "from scipy import __version__ as scipy_version\n",
    "from enum import Enum\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(precision=6)\n",
    "\n",
    "_USE_DCM_NAME = LooseVersion(scipy_version) < LooseVersion(\"1.4\")\n",
    "\n",
    "def csv_read_matrix(file_path, delim=',', comment_str=\"#\"):\n",
    "    \"\"\"\n",
    "    directly parse a csv-like file into a matrix\n",
    "    :param file_path: path of csv file (or file handle)\n",
    "    :param delim: delimiter character\n",
    "    :param comment_str: string indicating a comment line to ignore\n",
    "    :return: 2D list with raw data (string)\n",
    "    \"\"\"\n",
    "    if hasattr(file_path, 'read'):  # if file handle\n",
    "        generator = (line for line in file_path\n",
    "                     if not line.startswith(comment_str))\n",
    "        reader = csv.reader(generator, delimiter=delim)\n",
    "        mat = [row for row in reader]\n",
    "    else:\n",
    "        skip_3_bytes = has_utf8_bom(file_path)\n",
    "        with open(file_path) as f:\n",
    "            if skip_3_bytes:\n",
    "                f.seek(3)\n",
    "            generator = (line for line in f\n",
    "                         if not line.startswith(comment_str))\n",
    "            reader = csv.reader(generator, delimiter=delim)\n",
    "            mat = [row for row in reader]\n",
    "    return mat\n",
    "\n",
    "def has_utf8_bom(file_path):\n",
    "    \"\"\"\n",
    "    Checks if the given file starts with a UTF8 BOM\n",
    "    wikipedia.org/wiki/Byte_order_mark\n",
    "    \"\"\"\n",
    "    size_bytes = os.path.getsize(file_path)\n",
    "    if size_bytes < 3:\n",
    "        return False\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return not int(binascii.hexlify(f.read(3)), 16) ^ 0xEFBBBF\n",
    "\n",
    "def get_trajs(f_path):\n",
    "    raw_mat = csv_read_matrix(f_path,delim=' ')\n",
    "    error_msg = \"TUM trajectory files must have 8 entries per row and no trailing delimiter at the end of the rows (space)\"\n",
    "    if not raw_mat or (len(raw_mat) > 0 and len(raw_mat[0]) != 8):\n",
    "        raise error_msg\n",
    "    try:\n",
    "        mat = np.array(raw_mat).astype(float)\n",
    "    except ValueError:\n",
    "        raise error_msg\n",
    "    stamps = mat[:, 0]  # n x 1\n",
    "    xyz = mat[:, 1:4]  # n x 3\n",
    "    quat = mat[:, 4:]  # n x 4\n",
    "    quat = np.roll(quat, 1, axis=1)  # shift 1 column -> w in front column\n",
    "    return PoseTrajectory3D(xyz,quat,stamps)\n",
    "\n",
    "def sim3(r: torch.tensor, t: torch.tensor, s: float) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    :param r: SO(3) rotation matrix\n",
    "    :param t: 3x1 translation vector\n",
    "    :param s: positive, non-zero scale factor\n",
    "    :return: Sim(3) similarity transformation matrix\n",
    "    \"\"\"\n",
    "    sim3 = torch.eye(4,device=r.device)\n",
    "    sim3[:3, :3] = s * r\n",
    "    sim3[:3, 3] = t\n",
    "    return sim3\n",
    "\n",
    "def relative_se3(p1: torch.tensor, p2: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    :param p1, p2: SE(3) matrices\n",
    "    :return: the relative transformation p1^{⁻1} * p2\n",
    "    \"\"\"\n",
    "    return se3_inverse(p1)@ p2\n",
    "\n",
    "def se3_inverse(p: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    :param p: absolute SE(3) pose\n",
    "    :return: the inverted pose\n",
    "    \"\"\"\n",
    "    r_inv = p[:3, :3].T\n",
    "    t_inv = -r_inv@p[:3, 3]\n",
    "    return se3(r_inv, t_inv)\n",
    "\n",
    "def se3(r: torch.tensor = torch.eye(3),\n",
    "        t: torch.tensor = torch.tensor([0, 0, 0])) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    :param r: SO(3) rotation matrix\n",
    "    :param t: 3x1 translation vector\n",
    "    :return: SE(3) transformation matrix\n",
    "    \"\"\"\n",
    "    se3 = torch.eye(4,dtype=torch.float64, device=r.device)\n",
    "    se3[:3, :3] = r\n",
    "    se3[:3, 3] = t\n",
    "    return se3\n",
    "\n",
    "def umeyama_alignment(x: torch.tensor, y: torch.tensor,\n",
    "                      with_scale: bool = False):\n",
    "    \"\"\"\n",
    "    Computes the least squares solution parameters of an Sim(m) matrix\n",
    "    that minimizes the distance between a set of registered points.\n",
    "    Umeyama, Shinji: Least-squares estimation of transformation parameters\n",
    "                     between two point patterns. IEEE PAMI, 1991\n",
    "    :param x: mxn matrix of points, m = dimension, n = nr. of data points\n",
    "    :param y: mxn matrix of points, m = dimension, n = nr. of data points\n",
    "    :param with_scale: set to True to align also the scale (default: 1.0 scale)\n",
    "    :return: r, t, c - rotation matrix, translation vector and scale factor\n",
    "    \"\"\"\n",
    "    if x.shape != y.shape:\n",
    "        raise \"data matrices must have the same shape\"\n",
    "\n",
    "    # m = dimension, n = nr. of data points\n",
    "    m, n = x.shape\n",
    "\n",
    "    # means, eq. 34 and 35\n",
    "    mean_x = x.mean(axis=1)\n",
    "    mean_y = y.mean(axis=1)\n",
    "\n",
    "    # variance, eq. 36\n",
    "    # \"transpose\" for column subtraction\n",
    "    sigma_x = 1.0 / n * (norm_tensor(x - mean_x[:, None])**2)\n",
    "\n",
    "    # covariance matrix, eq. 38\n",
    "    outer_sum = torch.zeros((m, m), device=x.device)\n",
    "    for i in range(n):\n",
    "        outer_sum += torch.outer((y[:, i] - mean_y), (x[:, i] - mean_x))\n",
    "    cov_xy = 1.0 / n * outer_sum\n",
    "\n",
    "    # SVD (text betw. eq. 38 and 39)\n",
    "    u, d, v = torch.linalg.svd(cov_xy)\n",
    "    if torch.count_nonzero(d > torch.finfo(d.dtype).eps) < m - 1:\n",
    "        raise \"Degenerate covariance rank, Umeyama alignment is not possible\"\n",
    "\n",
    "    # S matrix, eq. 43\n",
    "    s = torch.eye(m, device=x.device)\n",
    "    if torch.linalg.det(u) * torch.linalg.det(v) < 0.0:\n",
    "        # Ensure a RHS coordinate system (Kabsch algorithm).\n",
    "        s[m - 1, m - 1] = -1\n",
    "\n",
    "    # rotation, eq. 40\n",
    "    r = ((u@s)@v).to(torch.float64)\n",
    "    # scale & translation, eq. 42 and 41\n",
    "    c = 1 / sigma_x * torch.trace(torch.diag(d)@s) if with_scale else 1.0\n",
    "    t = mean_y - torch.multiply(c, r@mean_x)\n",
    "\n",
    "    return r, t, c\n",
    "\n",
    "def scale(s: float, _poses_se3, _positions_xyz) -> None:\n",
    "    \"\"\"\n",
    "    apply a scaling to the whole path\n",
    "    :param s: scale factor\n",
    "    \"\"\"\n",
    "    # if hasattr(self, \"_poses_se3\"):\n",
    "    _poses_se3 = [\n",
    "        se3(p[:3, :3], s * p[:3, 3]) for p in _poses_se3\n",
    "    ]\n",
    "    # if hasattr(self, \"_positions_xyz\"):\n",
    "    _positions_xyz = s * _positions_xyz\n",
    "\n",
    "    return _poses_se3, _positions_xyz\n",
    "\n",
    "def quaternion_from_matrix(matrix, isprecise=False):\n",
    "    \"\"\"Return quaternion from rotation matrix.\n",
    "\n",
    "    If isprecise is True, the input matrix is assumed to be a precise rotation\n",
    "    matrix and a faster algorithm is used.\n",
    "    \"\"\"\n",
    "    M = torch.array(matrix, dtype=torch.float64, copy=False)[:4, :4]\n",
    "    if isprecise:\n",
    "        q = torch.empty((4, ), device=matrix.device)\n",
    "        t = torch.trace(M)\n",
    "        if t > M[3, 3]:\n",
    "            q[0] = t\n",
    "            q[3] = M[1, 0] - M[0, 1]\n",
    "            q[2] = M[0, 2] - M[2, 0]\n",
    "            q[1] = M[2, 1] - M[1, 2]\n",
    "        else:\n",
    "            i, j, k = 1, 2, 3\n",
    "            if M[1, 1] > M[0, 0]:\n",
    "                i, j, k = 2, 3, 1\n",
    "            if M[2, 2] > M[i, i]:\n",
    "                i, j, k = 3, 1, 2\n",
    "            t = M[i, i] - (M[j, j] + M[k, k]) + M[3, 3]\n",
    "            q[i] = t\n",
    "            q[j] = M[i, j] + M[j, i]\n",
    "            q[k] = M[k, i] + M[i, k]\n",
    "            q[3] = M[k, j] - M[j, k]\n",
    "        q *= 0.5 / torch.sqrt(t * M[3, 3])\n",
    "    else:\n",
    "        m00 = M[0, 0]\n",
    "        m01 = M[0, 1]\n",
    "        m02 = M[0, 2]\n",
    "        m10 = M[1, 0]\n",
    "        m11 = M[1, 1]\n",
    "        m12 = M[1, 2]\n",
    "        m20 = M[2, 0]\n",
    "        m21 = M[2, 1]\n",
    "        m22 = M[2, 2]\n",
    "        # symmetric matrix K\n",
    "        K = torch.tensor([[m00-m11-m22, 0.0,         0.0,         0.0],\n",
    "                         [m01+m10,     m11-m00-m22, 0.0,         0.0],\n",
    "                         [m02+m20,     m12+m21,     m22-m00-m11, 0.0],\n",
    "                         [m21-m12,     m02-m20,     m10-m01,     m00+m11+m22]], device=matrix.device)\n",
    "        K /= 3.0\n",
    "        # quaternion is eigenvector of K that corresponds to largest eigenvalue\n",
    "        w, V = torch.linalg.eigh(K)\n",
    "        q = V[[3, 0, 1, 2], torch.argmax(w)]\n",
    "    if q[0] < 0.0:\n",
    "        torch.negative(q, q)\n",
    "    return q\n",
    "\n",
    "def se3_poses_to_xyz_quat_wxyz(\n",
    "    poses: typing.Sequence[torch.tensor]\n",
    ") -> typing.Tuple[torch.tensor, torch.tensor]:\n",
    "    xyz = torch.tensor([pose[:3, 3] for pose in poses],requires_grad=True, device=poses.device)\n",
    "    quat_wxyz = torch.tensor([quaternion_from_matrix(pose) for pose in poses],requires_grad=True, device=poses.device)\n",
    "    return xyz, quat_wxyz\n",
    "\n",
    "def transform(t: torch.tensor, poses_se3, right_mul: bool = False,\n",
    "                propagate: bool = False) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    apply a left or right multiplicative transformation to the whole path\n",
    "    :param t: a 4x4 transformation matrix (e.g. SE(3) or Sim(3))\n",
    "    :param right_mul: whether to apply it right-multiplicative or not\n",
    "    :param propagate: whether to propagate drift with RHS transformations\n",
    "    \"\"\"\n",
    "    num_poses = len(poses_se3)\n",
    "    if right_mul and not propagate:\n",
    "        # Transform each pose individually.\n",
    "        _poses_se3 = [p@t for p in poses_se3]\n",
    "    elif right_mul and propagate:\n",
    "        # Transform each pose and propagate resulting drift to the next.\n",
    "        ids = torch.arange(0, num_poses, 1)\n",
    "        rel_poses = [\n",
    "            relative_se3(poses_se3[i], poses_se3[j]).dot(t)\n",
    "            for i, j in zip(ids, ids[1:])\n",
    "        ]\n",
    "        _poses_se3 = [poses_se3[0]]\n",
    "        for i, j in zip(ids[:-1], ids):\n",
    "            _poses_se3.append(_poses_se3[j].dot(rel_poses[i]))\n",
    "    else:\n",
    "        _poses_se3 = [t@p for p in poses_se3]\n",
    "    return _poses_se3\n",
    "\n",
    "def align_traj(traj_ref,traj_est, correct_scale: bool = False,\n",
    "            correct_only_scale: bool = False, n: int = -1):\n",
    "    \"\"\"\n",
    "    align to a reference trajectory using Umeyama alignment\n",
    "    :param traj_ref: reference trajectory\n",
    "    :param correct_scale: set to True to adjust also the scale\n",
    "    :param correct_only_scale: set to True to correct the scale, but not the pose\n",
    "    :param n: the number of poses to use, counted from the start (default: all)\n",
    "    :return: aligned trajectory\n",
    "    \"\"\"\n",
    "    with_scale = correct_scale or correct_only_scale\n",
    "    if n == -1:\n",
    "        r_a, t_a, s = umeyama_alignment(traj_est[:,:3,3].T, traj_ref[:,:3,3].T, with_scale)\n",
    "    else:\n",
    "        r_a, t_a, s = umeyama_alignment(\n",
    "            traj_est[:n,:3,3].T, traj_est[:n, :3,3].T,\n",
    "            with_scale)\n",
    "\n",
    "    poses_se3, positions_xyz = traj_est, traj_est[:,:3,3]\n",
    "\n",
    "    if correct_only_scale:\n",
    "        poses_se3, positions_xyz = scale(s,poses_se3,positions_xyz)\n",
    "    elif correct_scale:\n",
    "        poses_se3, positions_xyz = scale(s,poses_se3,positions_xyz)\n",
    "        poses_se3 = transform(se3(r_a, t_a),poses_se3)\n",
    "    else:\n",
    "        poses_se3 = transform(se3(r_a, t_a),poses_se3)\n",
    "    # traj_est.poses_se3, traj_est.positions_xyz = poses_se3, positions_xyz \n",
    "\n",
    "    return poses_se3\n",
    "\n",
    "def align_origin_traj(traj_ref, traj_est) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        align the origin to the origin of a reference trajectory\n",
    "        :param traj_ref: reference trajectory\n",
    "        :return: the used transformation\n",
    "        \"\"\"\n",
    "        traj_origin = traj_est[0]\n",
    "        traj_ref_origin = traj_ref[0]\n",
    "        to_ref_origin = traj_ref_origin@se3_inverse(traj_origin)\n",
    "        return to_ref_origin\n",
    "\n",
    "def ape(traj_ref, traj_est, align: bool = False, correct_scale: bool = False, \n",
    "        n_to_align: int = -1, align_origin: bool = False):\n",
    "\n",
    "    # Align the trajectories.\n",
    "    only_scale = correct_scale and not align\n",
    "    \n",
    "    if align or correct_scale:\n",
    "        traj_est = align_traj(traj_ref,traj_est, correct_scale, only_scale, n=n_to_align)\n",
    "    elif align_origin:\n",
    "        alignment_transformation = align_origin_traj(traj_ref, traj_est)\n",
    "        traj_est = transform(alignment_transformation,traj_est)\n",
    "    # Calculate APE.\n",
    "    data = (traj_ref, traj_est)\n",
    "    E = [\n",
    "        relative_se3(x_t, x_t_star) for x_t, x_t_star in zip(\n",
    "            traj_est, traj_ref)\n",
    "    ]\n",
    "    \n",
    "    error = torch.tensor(\n",
    "        [norm_tensor(E_i - torch.eye(4, device=traj_ref.device)) for E_i in E], requires_grad=True, device=traj_ref.device)\n",
    "\n",
    "    squared_errors = torch.pow(error, 2)\n",
    "    rmse = torch.sqrt(torch.mean(squared_errors))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "def norm_tensor(t):\n",
    "    return t.pow(2).sum().sqrt()\n",
    "\n",
    "groundtruth_file = '/home/rp2/Projects/slambook2/ch4/example/groundtruth.txt'\n",
    "estimated_file = '/home/rp2/Projects/slambook2/ch4/example/estimated.txt'\n",
    "\n",
    "traj_ref, traj_est, ref_name, est_name = get_trajs(groundtruth_file), get_trajs(estimated_file), groundtruth_file, estimated_file\n",
    "traj_ref, traj_est = sync.associate_trajectories(traj_ref, traj_est)\n",
    "traj_ref, traj_est = torch.tensor(traj_ref.poses_se3, requires_grad=True, dtype=torch.float64), torch.tensor(traj_est.poses_se3, requires_grad=True, dtype=torch.float64)\n",
    "res = ape(traj_ref=traj_ref, traj_est=traj_est,align=True, correct_scale=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('slam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7af58e923efb7b93f0099bb220d7fed445257007ef691093aec6003cd430dfa0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
